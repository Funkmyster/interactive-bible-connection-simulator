{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47dc422a-2382-4bb2-b193-95f334e50359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Step 1 (MVP v3.0): Setup for processing cross_references.txt\n",
      "Checking for input file: ./cross_references.txt\n",
      "Input file found: C:\\Users\\joshu\\OneDrive - Rick At Your Service Property Solutions\\Joshs Hobbies\\AppDevelopment\\interactive-bible-connection-simulator\\cross_references.txt\n",
      "Helper functions defined.\n",
      "Cell 1 Setup Complete. Proceed to Cell 2 for processing.\n",
      "Stored 'INPUT_TXT_PATH' (str)\n",
      "Stored 'OUTPUT_JSON_PATH' (str)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "import csv # Use csv module for robust TSV parsing\n",
    "\n",
    "print(\"Preprocessing Step 1 (MVP v3.0): Setup for processing cross_references.txt\")\n",
    "\n",
    "# --- Configuration ---\n",
    "# Adjust path relative to your notebook's location\n",
    "INPUT_TXT_PATH = './cross_references.txt' # Path to your source TSV file\n",
    "OUTPUT_JSON_PATH = '../data/references.json' # Path relative to notebook to project's data folder\n",
    "\n",
    "# --- Book Name Normalization Helper ---\n",
    "# CRITICAL: This map's keys must cover variants in the TXT file (e.g., \"Gen.\", \"Ps.\")\n",
    "# Values MUST match the canonical names used in canonicalOrder.js and for BSB.json lookups\n",
    "# Case-insensitive matching will be used.\n",
    "BOOK_NAME_MAP = {\n",
    "    'gen': 'Genesis', 'exod': 'Exodus', 'lev': 'Leviticus', 'num': 'Numbers', 'deut': 'Deuteronomy',\n",
    "    'josh': 'Joshua', 'judg': 'Judges', 'ruth': 'Ruth', '1sam': '1 Samuel', '2sam': '2 Samuel',\n",
    "    '1kgs': '1 Kings', '2kgs': '2 Kings', '1chr': '1 Chronicles', '2chr': '2 Chronicles', 'ezra': 'Ezra',\n",
    "    'neh': 'Nehemiah', 'est': 'Esther', 'job': 'Job', 'ps': 'Psalms', 'prov': 'Proverbs',\n",
    "    'eccl': 'Ecclesiastes', 'song': 'Song of Solomon',\n",
    "    'isa': 'Isaiah', 'jer': 'Jeremiah', 'lam': 'Lamentations', 'ezek': 'Ezekiel', 'dan': 'Daniel',\n",
    "    'hos': 'Hosea', 'joel': 'Joel', 'amos': 'Amos', 'obad': 'Obadiah', 'jonah': 'Jonah', 'mic': 'Micah',\n",
    "    'nah': 'Nahum', 'hab': 'Habakkuk', 'zeph': 'Zephaniah', 'hag': 'Haggai', 'zech': 'Zechariah', 'mal': 'Malachi',\n",
    "    'matt': 'Matthew', 'mark': 'Mark', 'luke': 'Luke', 'john': 'John', 'acts': 'Acts', 'rom': 'Romans',\n",
    "    '1cor': '1 Corinthians', '2cor': '2 Corinthians', 'gal': 'Galatians', 'eph': 'Ephesians',\n",
    "    'phil': 'Philippians', 'col': 'Colossians', '1thess': '1 Thessalonians', '2thess': '2 Thessalonians',\n",
    "    '1tim': '1 Timothy', '2tim': '2 Timothy', 'titus': 'Titus', 'phlm': 'Philemon', 'heb': 'Hebrews', 'jas': 'James',\n",
    "    '1pet': '1 Peter', '2pet': '2 Peter', '1jn': '1 John', '1john': '1 John', # Allow both if needed\n",
    "    '2jn': '2 John', '2john': '2 John', '3jn': '3 John', '3john': '3 John', 'jude': 'Jude',\n",
    "    'rev': 'Revelation of John' # Match canonical name\n",
    "}\n",
    "\n",
    "def normalize_book_name_from_txt(raw_name):\n",
    "    if not raw_name: return None\n",
    "    # Remove periods, leading/trailing whitespace, convert to lower case\n",
    "    cleaned = raw_name.strip().replace('.', '').lower()\n",
    "    # Handle cases like '1 samuel' -> '1samuel' if map uses that format\n",
    "    # This basic version just removes spaces for lookup - adjust if map keys have spaces\n",
    "    lookup_key = cleaned.replace(' ', '')\n",
    "    normalized = BOOK_NAME_MAP.get(lookup_key)\n",
    "    if not normalized:\n",
    "         # Try direct match on cleaned name if map key didn't work\n",
    "         normalized = BOOK_NAME_MAP.get(cleaned)\n",
    "\n",
    "    # if not normalized: # Optional: Warn about unmapped names\n",
    "        # print(f\"Warning: No normalization map found for '{raw_name}' (cleaned: '{cleaned}')\")\n",
    "    # Fallback to a cleaned version or None if mapping is required\n",
    "    return normalized if normalized else cleaned.title() # Return Title Case cleaned name as fallback\n",
    "\n",
    "\n",
    "# --- Reference String Parsing Helper ---\n",
    "# Parses strings like \"Gen.1.1\", \"1Sam.2.3\"\n",
    "# Returns (normalized_book_name, chapter, verse) or None\n",
    "def parse_dot_reference(ref_str):\n",
    "    if not ref_str: return None\n",
    "    # Regex: Book(may contain . or space).Chapter.Verse\n",
    "    match = re.match(r'^([1-3]?[\\s\\w\\.]+)\\.(\\d+)\\.(\\d+)$', ref_str.strip(), re.IGNORECASE)\n",
    "    if match:\n",
    "        raw_book, chapter_str, verse_str = match.groups()\n",
    "        normalized_book = normalize_book_name_from_txt(raw_book)\n",
    "        if normalized_book:\n",
    "            try:\n",
    "                return (normalized_book, int(chapter_str), int(verse_str))\n",
    "            except ValueError:\n",
    "                return None # Failed converting numbers\n",
    "    return None\n",
    "\n",
    "# --- Function to create the final ID string ---\n",
    "# Format: BookNameChvVs (e.g., Genesis1v1, John3v16) - no spaces\n",
    "def format_id_string(book, chapter, verse):\n",
    "     # Remove spaces from the canonical book name for the ID\n",
    "     book_id_part = book.replace(' ', '')\n",
    "     return f\"{book_id_part}{chapter}v{verse}\"\n",
    "\n",
    "\n",
    "print(f\"Checking for input file: {INPUT_TXT_PATH}\")\n",
    "if not os.path.exists(INPUT_TXT_PATH):\n",
    "     print(f\"ERROR: Input file not found at '{os.path.abspath(INPUT_TXT_PATH)}'\")\n",
    "     print(\"Please ensure 'cross_references.txt' is in the correct location or update INPUT_TXT_PATH.\")\n",
    "else:\n",
    "     print(f\"Input file found: {os.path.abspath(INPUT_TXT_PATH)}\")\n",
    "     print(\"Helper functions defined.\")\n",
    "     print(\"Cell 1 Setup Complete. Proceed to Cell 2 for processing.\")\n",
    "\n",
    "# Store paths/helpers if needed across cells (less critical now but can be useful)\n",
    "%store INPUT_TXT_PATH\n",
    "%store OUTPUT_JSON_PATH\n",
    "# Storing functions isn't standard, just ensure they are defined before use in Cell 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcd250e4-b0f4-4408-b186-9e0b354398a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Step 2 (MVP v3.0): Reading TXT File and Formatting Data\n",
      "Skipped header: ['From Verse', 'To Verse', 'Votes', '#www.openbible.info CC-BY 2025-03-24']\n",
      "\n",
      "--- Processing Summary ---\n",
      "Total rows processed (excluding header): 344799\n",
      "Rows successfully converted to reference objects: 344799\n",
      "Rows skipped (due to format/value errors): 0\n",
      "  - Estimated individual parse errors: 0\n",
      "Length of all_references list: 344799\n",
      "\n",
      "Cell 2 Processing Complete. Check summary. Proceed to Cell 3 for writing JSON.\n",
      "Stored 'all_references' (list)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import re # Re-import just in case kernel restarted\n",
    "\n",
    "# --- Restore variables if needed (or redefine if kernel restarted) ---\n",
    "# %store -r INPUT_TXT_PATH\n",
    "# %store -r OUTPUT_JSON_PATH\n",
    "# Make sure helper functions from Cell 1 are accessible (re-run Cell 1 if needed)\n",
    "\n",
    "print(\"Preprocessing Step 2 (MVP v3.0): Reading TXT File and Formatting Data\")\n",
    "\n",
    "all_references = []\n",
    "processed_rows = 0\n",
    "skipped_rows = 0\n",
    "parse_errors = 0\n",
    "\n",
    "# Re-define helpers just in case kernel was restarted\n",
    "# (Copying from Cell 1 for robustness)\n",
    "BOOK_NAME_MAP = {\n",
    "    'gen': 'Genesis', 'exod': 'Exodus', 'lev': 'Leviticus', 'num': 'Numbers', 'deut': 'Deuteronomy',\n",
    "    'josh': 'Joshua', 'judg': 'Judges', 'ruth': 'Ruth', '1sam': '1 Samuel', '2sam': '2 Samuel',\n",
    "    '1kgs': '1 Kings', '2kgs': '2 Kings', '1chr': '1 Chronicles', '2chr': '2 Chronicles', 'ezra': 'Ezra',\n",
    "    'neh': 'Nehemiah', 'est': 'Esther', 'job': 'Job', 'ps': 'Psalms', 'prov': 'Proverbs',\n",
    "    'eccl': 'Ecclesiastes', 'song': 'Song of Solomon',\n",
    "    'isa': 'Isaiah', 'jer': 'Jeremiah', 'lam': 'Lamentations', 'ezek': 'Ezekiel', 'dan': 'Daniel',\n",
    "    'hos': 'Hosea', 'joel': 'Joel', 'amos': 'Amos', 'obad': 'Obadiah', 'jonah': 'Jonah', 'mic': 'Micah',\n",
    "    'nah': 'Nahum', 'hab': 'Habakkuk', 'zeph': 'Zephaniah', 'hag': 'Haggai', 'zech': 'Zechariah', 'mal': 'Malachi',\n",
    "    'matt': 'Matthew', 'mark': 'Mark', 'luke': 'Luke', 'john': 'John', 'acts': 'Acts', 'rom': 'Romans',\n",
    "    '1cor': '1 Corinthians', '2cor': '2 Corinthians', 'gal': 'Galatians', 'eph': 'Ephesians',\n",
    "    'phil': 'Philippians', 'col': 'Colossians', '1thess': '1 Thessalonians', '2thess': '2 Thessalonians',\n",
    "    '1tim': '1 Timothy', '2tim': '2 Timothy', 'titus': 'Titus', 'phlm': 'Philemon', 'heb': 'Hebrews', 'jas': 'James',\n",
    "    '1pet': '1 Peter', '2pet': '2 Peter', '1jn': '1 John', '1john': '1 John', # Allow both if needed\n",
    "    '2jn': '2 John', '2john': '2 John', '3jn': '3 John', '3john': '3 John', 'jude': 'Jude',\n",
    "    'rev': 'Revelation of John' # Match canonical name\n",
    "}\n",
    "def normalize_book_name_from_txt(raw_name):\n",
    "    if not raw_name: return None\n",
    "    cleaned = raw_name.strip().replace('.', '').lower()\n",
    "    lookup_key = cleaned.replace(' ', '')\n",
    "    normalized = BOOK_NAME_MAP.get(lookup_key)\n",
    "    if not normalized: normalized = BOOK_NAME_MAP.get(cleaned) # Try with space if first failed\n",
    "    # Fallback logic can be adjusted\n",
    "    return normalized if normalized else cleaned.title() # Fallback to title case cleaned name\n",
    "\n",
    "def parse_dot_reference(ref_str):\n",
    "    if not ref_str: return None\n",
    "    match = re.match(r'^([1-3]?[\\s\\w\\.]+)\\.(\\d+)\\.(\\d+)$', ref_str.strip(), re.IGNORECASE)\n",
    "    if match:\n",
    "        raw_book, chapter_str, verse_str = match.groups()\n",
    "        normalized_book = normalize_book_name_from_txt(raw_book)\n",
    "        if normalized_book:\n",
    "            try: return (normalized_book, int(chapter_str), int(verse_str))\n",
    "            except ValueError: return None\n",
    "    return None\n",
    "\n",
    "def format_id_string(book, chapter, verse):\n",
    "     book_id_part = book.replace(' ', '') # Ensure no spaces in final ID\n",
    "     return f\"{book_id_part}{chapter}v{verse}\"\n",
    "# --- End re-defined helpers ---\n",
    "\n",
    "\n",
    "try:\n",
    "    with open(INPUT_TXT_PATH, mode='r', newline='', encoding='utf-8') as infile:\n",
    "        # Use csv.reader with tab delimiter\n",
    "        reader = csv.reader(infile, delimiter='\\t')\n",
    "\n",
    "        # Skip header row\n",
    "        header = next(reader)\n",
    "        print(f\"Skipped header: {header}\")\n",
    "\n",
    "        # Process data rows\n",
    "        for i, row in enumerate(reader):\n",
    "            if len(row) == 3: # Expecting 3 columns\n",
    "                from_verse_str, to_verse_str, votes_str = row\n",
    "\n",
    "                # Handle ranges in 'To Verse' - take start verse only\n",
    "                # Split by '-', take the first part, strip whitespace\n",
    "                target_ref_str = to_verse_str.split('-')[0].strip()\n",
    "\n",
    "                # Parse 'From' and 'Target' (start of range)\n",
    "                from_parsed = parse_dot_reference(from_verse_str)\n",
    "                target_parsed = parse_dot_reference(target_ref_str)\n",
    "\n",
    "                if from_parsed and target_parsed:\n",
    "                    try:\n",
    "                        votes = int(votes_str.strip())\n",
    "\n",
    "                        # Format IDs\n",
    "                        source_id = format_id_string(*from_parsed)\n",
    "                        target_id = format_id_string(*target_parsed)\n",
    "\n",
    "                        # Create JSON object (value is votes)\n",
    "                        reference_obj = {\n",
    "                            \"source\": source_id,\n",
    "                            \"target\": target_id,\n",
    "                            \"value\": votes\n",
    "                        }\n",
    "                        all_references.append(reference_obj)\n",
    "                        processed_rows += 1\n",
    "\n",
    "                    except ValueError:\n",
    "                        # print(f\"Warning: Skipping row {i+2} due to invalid votes value: '{votes_str}'\")\n",
    "                        skipped_rows += 1\n",
    "                        parse_errors += 1\n",
    "                else:\n",
    "                    # print(f\"Warning: Skipping row {i+2} due to invalid reference format: '{from_verse_str}' or '{target_ref_str}'\")\n",
    "                    skipped_rows += 1\n",
    "                    if not from_parsed: parse_errors += 1\n",
    "                    if not target_parsed: parse_errors += 1\n",
    "            else:\n",
    "                # print(f\"Warning: Skipping row {i+2} due to unexpected number of columns: {len(row)}\")\n",
    "                skipped_rows += 1\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Input file not found at '{INPUT_TXT_PATH}'\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during processing: {e}\")\n",
    "\n",
    "print(f\"\\n--- Processing Summary ---\")\n",
    "print(f\"Total rows processed (excluding header): {processed_rows + skipped_rows}\")\n",
    "print(f\"Rows successfully converted to reference objects: {processed_rows}\")\n",
    "print(f\"Rows skipped (due to format/value errors): {skipped_rows}\")\n",
    "print(f\"  - Estimated individual parse errors: {parse_errors}\") # Note: A row skip might involve multiple parse errors\n",
    "print(f\"Length of all_references list: {len(all_references)}\")\n",
    "\n",
    "print(\"\\nCell 2 Processing Complete. Check summary. Proceed to Cell 3 for writing JSON.\")\n",
    "\n",
    "# Store results for next cell\n",
    "%store all_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb43c704-5393-4635-809d-7508d8f62125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Step 3 (MVP v3.0): Writing Data to JSON file\n",
      "no stored variable or alias #\n",
      "no stored variable or alias This\n",
      "no stored variable or alias should\n",
      "no stored variable or alias be\n",
      "no stored variable or alias '../data/references.json'\n",
      "Creating output directory: ../data\n",
      "Writing 344799 references to ../data/references.json...\n",
      "Successfully wrote C:\\Users\\joshu\\OneDrive - Rick At Your Service Property Solutions\\Joshs Hobbies\\AppDevelopment\\data\\references.json\n",
      "Preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "print(\"Preprocessing Step 3 (MVP v3.0): Writing Data to JSON file\")\n",
    "\n",
    "# --- Restore variables ---\n",
    "%store -r all_references\n",
    "%store -r OUTPUT_JSON_PATH # This should be '../data/references.json'\n",
    "\n",
    "output_dir = os.path.dirname(OUTPUT_JSON_PATH)\n",
    "\n",
    "try:\n",
    "    # Ensure the output directory exists\n",
    "    if output_dir and not os.path.exists(output_dir):\n",
    "        print(f\"Creating output directory: {output_dir}\")\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Write the data to the JSON file\n",
    "    print(f\"Writing {len(all_references)} references to {OUTPUT_JSON_PATH}...\")\n",
    "    with open(OUTPUT_JSON_PATH, 'w', encoding='utf-8') as f:\n",
    "        # Use indent=None for smallest file size for production data\n",
    "        json.dump(all_references, f, ensure_ascii=False, indent=None)\n",
    "\n",
    "    print(f\"Successfully wrote {os.path.abspath(OUTPUT_JSON_PATH)}\")\n",
    "    print(\"Preprocessing complete.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR writing JSON file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6605d6-eff3-41e3-b7a9-dd4fc7100fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
